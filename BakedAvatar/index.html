<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="BakedAvatar: Baking Neural Fields for Real-Time Head Avatar Synthesis">
  <meta name="keywords" content="Head Avatar Synthesis, Face Reenactment, Neural Radiance Fields">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>BakedAvatar</title>

  <!-- Bootstrap -->
  <link href="static/css/bootstrap-4.4.1.css" rel="stylesheet">
  
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-V2NT8PJYCQ"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-V2NT8PJYCQ');
  </script>

  <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h2 class="title is-2 publication-title" style="margin-top: 0; margin-bottom: 0">BakedAvatar: Baking Neural Fields for Real-Time Head Avatar Synthesis</h2>
          <br/>
          <h2 class="title is-5 publication-title" style="color:#6e6e6e;margin-top: 2; margin-bottom: 2">ACM Transactions on Graphics (SIGGRAPH Asia 2023)</h2>
  

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Hao-Bin Duan<sup>1</sup>
            </span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              <a href="http://miaowang.me/">Miao Wang</a><sup>1, 2</sup>
            </span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              Jin-Chuan Shi<sup>1</sup>
            </span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              Xu-Chuan Chen<sup>1</sup>
            </span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              <a href="https://yanpei.me/">Yan-Pei Cao</a><sup>3</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>State Key Laboratory of Virtual Reality Technology and Systems, Beihang University</span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"><sup>2</sup>Zhongguancun Laboratory</span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"><sup>3</sup>ARC Lab, Tencent PCG</span>&nbsp;&nbsp;&nbsp;&nbsp;
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!--
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              -->
              <span class="link-block">
                <a class="external-link button is-normal is-rounded is-dark" href="https://arxiv.org/abs/2311.05521">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!--
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              -->
              <!-- Code Link. -->
              <span class="link-block">
                <a class="external-link button is-normal is-rounded is-dark disabled" href="https://github.com/buaavrcg/BakedAvatar">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!--
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>
              -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!--
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./resources/teaser.png"
                type="video/mp4">
      </video>
      -->
      <img src="./resources/teaser.jpg" class="center">
      <h2 class="subtitle has-text-centered" style="margin-top: 15px">
        TL;DR: BakedAvatar takes monocular video recordings of a person and produces a mesh-based representation for real-time 4D head avatar synthesis on various devices including mobiles.
      </h2>
    </div>
  </div>
</section>

<!--
<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Reconstructions</h2>

        <div class="embed-responsive embed-responsive-16by9">

          <iframe style="clip-path: inset(1px 1px)" src="https://sketchfab.com/playlists/embed?collection=abee3cc1a7a7436c804f2bd3aadc2acd" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture; fullscreen" mozallowfullscreen="true" webkitallowfullscreen="true" width="100%" height="100%" frameborder="0"></iframe>
        </div>
        

      </div>
    </div>

  </div>
</section>

-->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="margin-top: -30px">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Synthesizing photorealistic 4D human head avatars from videos is essential for VR/AR, telepresence, and video game applications. 
            Although existing Neural Radiance Fields (NeRF)-based methods achieve high-fidelity results, the computational expense limits their use in real-time applications. 
            To overcome this limitation, we introduce BakedAvatar, a novel representation for real-time neural head avatar synthesis, deployable in a standard polygon rasterization pipeline. 
            Our approach extracts deformable multi-layer meshes from learned isosurfaces of the head and computes expression-, pose-, and view-dependent appearances that can be baked into static textures for efficient rasterization. 
            We thus propose a three-stage pipeline for neural head avatar synthesis, which includes learning continuous deformation, manifold, and radiance fields, extracting layered meshes and textures, and fine-tuning texture details with differential rasterization. 
            Experimental results demonstrate that our representation generates synthesis results of comparable quality to other state-of-the-art methods while significantly reducing the inference time required. 
            We further showcase various head avatar synthesis results from monocular videos, including view synthesis, face reenactment, expression editing, and pose editing, all at interactive frame rates.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <!-- Paper video. -->
    <!--
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    -->
    <!--/ Paper video. -->
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="margin-top: -20px">Method</h2>

        <img src="./resources/pipeline.png" class="center">
        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            Overview of our three-stage pipeline. 
            In the first stage, we learn three implicit fields in canonical space for FLAME-based deformation, isosurface geometry, 
            as well as multiple radiance bases and a position feature that are combined by the light-weighted appearance decoder. 
            In the second stage, we bake these neural fields as deformable multi-layer meshes and multiple static textures. 
            In the third stage, we use differential rasterization to fine-tune the baked textures.
          </p>
        </div>

      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Results. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Results</h2>

        <div class="content has-text-justified">
          <p>
            We test our method on multiple monocular videos of real portrait videos from 
            PointAvatar [Zheng et al. 2022b], NHA [Grassal et al. 2022], NerFace [Gafniet al. 2021], and HDTF [Zhang et al. 2021].
          </p>
        </div>
        

        <div class="content has-text-centered">
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 loop
                 width="100%">
            <source src="./resources/task.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>

  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Comparisons. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Comparisons</h2>

        <div class="content has-text-justified">
          <p>
            We compare our method with state-of-the-art neural head avatar reconsturction methods.
          </p>
        </div>
 
        <div class="content has-text-centered">
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 loop
                 width="100%">
            <source src="./resources/comparison.mp4" type="video/mp4">
          </video>
        </div>

      </div>
    </div>

  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Ablation Studies. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Controlled Head Avatar Synthesis</h2>

        <div class="content has-text-justified">
          <p>
          Our method supports real-time rendering of controllable head avatars.
          We test our method on novel-view synthesis, facial reenactment, expression and pose editing task.
          </p>
        </div>

        <div class="content has-text-centered">
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 loop
                 width="85%">
            <source src="./resources/novelview.mp4" type="video/mp4">
          </video>
        </div>
        
        <div class="content has-text-centered">
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 loop
                 width="85%">
            <source src="./resources/reenactment.mp4" type="video/mp4">
          </video>
        </div>

        <div class="content has-text-centered">
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 loop
                 width="85%">
            <source src="./resources/editing.mp4" type="video/mp4">
          </video>
        </div>

      </div>
    </div>

  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Comparisons. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Real-time Rendering</h2>

        <div class="content has-text-justified">
          <p>
            Our method renders 4D head avatars at real-time framerates on mobiles devices.
          </p>
        </div>
 
        <div class="content has-text-centered">
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 loop
                 width="90%">
            <source src="./resources/speed.mp4" type="video/mp4">
          </video>
        </div>

      </div>
    </div>

  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    
    <div class="content has-text-justified">
      <p>
        If you find this work useful for your work, please cite us:
      </p>
    </div>

    <pre><code>@article{bakedavatar,
  author = {Duan, Hao-Bin and Wang, Miao and Shi, Jin-Chuan and Chen, Xu-Chuan and Cao, Yan-Pei},
  title = {BakedAvatar: Baking Neural Fields for Real-Time Head Avatar Synthesis},
  year = {2023},
  issue_date = {December 2023},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3618399},
  doi = {10.1145/3618399},
  volume = {42},
  number = {6},
  journal = {ACM Trans. Graph.},
  month = {sep},
  articleno = {225},
  numpages = {14}
}</code></pre>
  </div>
</section>



<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    The authors express gratitude to the anonymous reviewers for their valuable feedback. 
    This work was supported by the National Natural Science Foundation of China (Project Number: 61932003) and the Fundamental Research Funds for the Central Universities. 
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
            This webpage template is from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. 
            We sincerely thank <a href="https://keunhong.com/">Keunhong Park</a> for developing and open-sourcing this template.
          </p>
        </div>
      </div>
          <p></p>
        </div>
      </div>
</footer>

</body>
</html>
